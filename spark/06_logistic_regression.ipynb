{
 "metadata": {
  "name": "",
  "signature": "sha256:bb0741f0a01e27e2dd58a42f24c59d8a131b69a6aa90511e846cba98b1211fd1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn import datasets\n",
      "from sklearn.utils import shuffle\n",
      "\n",
      "random_state = np.random.RandomState(0)\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "X = iris.data\n",
      "y = iris.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make it a binary classification problem by removing the third class"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = X[y != 0], y[y != 0]\n",
      "n_samples, n_features = X.shape\n",
      "\n",
      "y[y==1] = 0\n",
      "y[y==2] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape, y.shape\n",
      "print set(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 4) (100,)\n",
        "set([0, 1])\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using `sklearn`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "clf = LogisticRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "y_pred_test = clf.predict(X_test)\n",
      "y_pred_train = clf.predict(X_train)\n",
      "print accuracy_score(y_test, y_pred_test)\n",
      "print accuracy_score(y_train, y_pred_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.85\n",
        "0.9875\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Save to file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print y_train.shape\n",
      "print y_train.reshape(y_train.shape[0],1).shape\n",
      "print X_train.shape\n",
      "cX = np.concatenate((y_train.reshape(80,1), X_train), axis=1)\n",
      "cX.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(80,)\n",
        "(80, 1)\n",
        "(80, 4)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(80, 5)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write to file...."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt('iris_train.csv', cX, delimiter=' ', fmt='%0.4f')\n",
      "!head iris_train.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0000 7.6000 3.0000 6.6000 2.1000\r\n",
        "1.0000 6.0000 3.0000 4.8000 1.8000\r\n",
        "0.0000 6.8000 2.8000 4.8000 1.4000\r\n",
        "0.0000 5.8000 2.6000 4.0000 1.2000\r\n",
        "1.0000 6.0000 2.2000 5.0000 1.5000\r\n",
        "0.0000 6.7000 3.1000 4.4000 1.4000\r\n",
        "0.0000 5.5000 2.6000 4.4000 1.2000\r\n",
        "1.0000 6.3000 2.5000 5.0000 1.9000\r\n",
        "0.0000 5.2000 2.7000 3.9000 1.4000\r\n",
        "1.0000 7.7000 2.8000 6.7000 2.0000\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cX = np.concatenate((y_test.reshape(len(y_test),1), X_test), axis=1)\n",
      "np.savetxt('iris_test.csv', cX, delimiter=' ', fmt='%0.4f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "With `Spark`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import  SparkContext\n",
      "sc = SparkContext( 'local[4]', 'pyspark')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "points = sc.textFile('iris_train.csv') #across 10 cpus\n",
      "points.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[u'1.0000 7.6000 3.0000 6.6000 2.1000',\n",
        " u'1.0000 6.0000 3.0000 4.8000 1.8000',\n",
        " u'0.0000 6.8000 2.8000 4.8000 1.4000',\n",
        " u'0.0000 5.8000 2.6000 4.0000 1.2000',\n",
        " u'1.0000 6.0000 2.2000 5.0000 1.5000']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
      "\n",
      "parsed_data = points.map(lambda line: np.array([float(x) for x in line.split(' ')]))\n",
      "parsed_data.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[array([ 1. ,  7.6,  3. ,  6.6,  2.1]),\n",
        " array([ 1. ,  6. ,  3. ,  4.8,  1.8]),\n",
        " array([ 0. ,  6.8,  2.8,  4.8,  1.4]),\n",
        " array([ 0. ,  5.8,  2.6,  4. ,  1.2]),\n",
        " array([ 1. ,  6. ,  2.2,  5. ,  1.5])]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LogisticRegressionWithSGD.train(parsed_data)\n",
      "\n",
      "y = parsed_data.map(lambda x: int(x[0]))\n",
      "y.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'numpy.ndarray' object has no attribute 'features'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-11-bb5a2ac1a9b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionWithSGD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/opt/spark/spark-1.0.0/python/pyspark/mllib/classification.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cls, data, iterations, step, miniBatchFraction, initialWeights)\u001b[0m\n\u001b[0;32m     76\u001b[0m             d._jrdd, iterations, step, miniBatchFraction, i)\n\u001b[0;32m     77\u001b[0m         return _regression_train_wrapper(sc, train_func, LogisticRegressionModel, data,\n\u001b[1;32m---> 78\u001b[1;33m                                          initialWeights)\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/opt/spark/spark-1.0.0/python/pyspark/mllib/_common.py\u001b[0m in \u001b[0;36m_regression_train_wrapper\u001b[1;34m(sc, train_func, klass, data, initial_weights)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;31m# _regression_train_wrapper is responsible for setup and error checking.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_regression_train_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m     \u001b[0minitial_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_initial_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m     \u001b[0mdataBytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_unmangled_labeled_point_rdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataBytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_serialize_double_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/opt/spark/spark-1.0.0/python/pyspark/mllib/_common.py\u001b[0m in \u001b[0;36m_get_initial_weights\u001b[1;34m(initial_weights, data)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_initial_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_weights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0minitial_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minitial_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'features'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred = parsed_data.map(lambda x: model.predict(x[1:]))\n",
      "y_pred.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[1, 1, 0, 0, 1]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = y.zip(y_pred)\n",
      "tmp.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[(1, 1), (1, 1), (0, 0), (0, 0), (1, 1)]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1.0 - tmp.filter(lambda (y, p): y!=p).count()/float(parsed_data.count())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.975"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "points = sc.textFile('iris_test.csv',10) #across 10 cpus\n",
      "parsed_data = points.map(lambda line: np.array([float(x) for x in line.split(' ')]))\n",
      "tmp = parsed_data.map(lambda x: (int(x[0]), model.predict(x[1:])))\n",
      "1.0 - tmp.filter(lambda (y, p): y!=p).count()/float(parsed_data.count())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.9"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}